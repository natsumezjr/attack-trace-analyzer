# 注册与轮询

## 文档目的

本文件定义中心机侧客户机注册、注册表结构、轮询调度与状态更新的固定行为，作为中心机“单定时轮询”的实现说明。

## 读者对象

- 负责中心机后端实现的同学
- 负责靶场联调与排障的同学

## 引用关系

- 权威接口规范：`../../80-规范/87-客户机与中心机接口.md`
- OpenSearch 索引规范：`../../80-规范/82-OpenSearch索引与Mapping规范.md`
- 中心机总体：`60-总体与代码结构.md`

## 1. 注册表结构

中心机以 OpenSearch 索引 `client-registry` 作为客户机注册表的唯一权威数据源。

注册表文档包含以下核心信息：

- `client.id`：客户机唯一 ID
- `client.listen_url`：客户机拉取接口基地址，例如 `http://10.0.0.11:8888`
- `client.capabilities`：三类数据源能力声明（falco、suricata、filebeat）
- `poll.last_seen`：最近一次轮询时间
- `poll.status`：最近一次轮询状态
- `poll.last_error`：最近一次轮询错误信息

字段结构与索引约束由 `../../80-规范/82-OpenSearch索引与Mapping规范.md` 与 `../../80-规范/87-客户机与中心机接口.md` 定义。

## 2. 注册流程

中心机提供客户机注册接口，注册成功后必须写入 `client-registry`：

- `POST /api/v1/clients/register`

接口请求与响应的权威定义见：

- `../../80-规范/87-客户机与中心机接口.md`

注册失败时不允许降级为“仅内存登记”，必须返回错误并保持注册表不变。

## 3. 轮询调度

### 3.1 实现位置

轮询服务实现文件：

- `backend/app/services/client_poller.py`

### 3.2 轮询周期与超时

轮询周期与超时由环境变量控制（默认值写死在代码中）：

- `CENTER_POLL_INTERVAL_SECONDS`：默认 `5`
- `CENTER_POLL_TIMEOUT_SECONDS`：默认 `5`

环境变量的权威清单与默认值见：

- `../../80-规范/89-环境变量与配置规范.md`

### 3.3 单轮询流程

轮询服务（单定时器 tick）的固定流程为：

```mermaid
flowchart TD
    Start([定时器触发 tick]) --> ReadRegistry["读取 client-registry"]

    ReadRegistry --> CheckEmpty{注册表<br/>是否为空?}
    CheckEmpty -->|是| End([结束本 tick])
    CheckEmpty -->|否| LoopStart

    subgraph Loop["遍历每个客户机"]
        LoopStart["获取 client 信息<br/>id, listen_url, capabilities"] --> CapsContent

        subgraph ParseCaps["解析 capabilities"]
            CapsContent["falco: true/false<br/>filebeat: true/false<br/>suricata: true/false"]
        end

        CapsContent --> FetchRoutes

        subgraph FetchRoutes["按 capabilities 拉取路由"]
            direction LR
            F1["GET {listen_url}/falco"] --> E1
            F2["GET {listen_url}/filebeat"] --> E2
            F3["GET {listen_url}/suricata"] --> E3
            E1((汇总事件))
            E2((汇总事件))
            E3((汇总事件))
        end

        E1 & E2 & E3 --> ExtractData["提取 data 数组<br/>汇总事件列表"]
        ExtractData --> UpdateStatus["更新 poll.*<br/>last_seen, status, error"]
        UpdateStatus --> NextClient{下一个<br/>客户机?}
        NextClient -->|是| LoopStart
        NextClient -->|否| AllDone
    end

    AllDone["所有客户机拉取完成"] --> StoreEvents

    subgraph Pipeline["中心机流水线 (严格顺序)"]
        direction TB
        StoreEvents["Step 2: store_events<br/>写入 OpenSearch<br/>字段处理/去重/路由"]

        subgraph Step3["Step 3: run_data_analysis"]
            Detect["Security Analytics<br/>检测"]
            Fusion["融合去重<br/>Raw → Canonical"]
            Detect --> Fusion
        end

        Step4["Step 4: ingest_from_opensearch_ingested_window<br/>ECS → Graph<br/>写入 Neo4j"]

        StoreEvents --> Step3
        Step3 --> Step4
    end

    Step4 --> End

    %% 统一配色方案
    %% 后端/API：绿色 (#e8f5e9 / #1b5e20)
    %% 客户机：蓝色 (#e1f5fe / #0277bd)
    %% 数据库：深蓝 (#e3f2fd / #1565c0)

    classDef controlStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    classDef clientStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000
    classDef backendStyle fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px,color:#000
    classDef dbStyle fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#000
    classDef eventStyle fill:#fff9c4,stroke:#f57f17,stroke-width:2px,color:#000

    class Start,End,CheckEmpty,NextClient controlStyle
    class ReadRegistry,LoopStart,CapsContent,FetchRoutes,ExtractData,UpdateStatus clientStyle
    class StoreEvents,Step3,Detect,Fusion,Step4 backendStyle
    class F1,F2,F3 dbStyle
    class E1,E2,E3 eventStyle
```

**流程说明**：

1. **注册表读取**：从 OpenSearch 读取 `client-registry` 的客户机列表；
2. **客户机遍历**：对每个客户机解析 `client.id`、`client.listen_url`、`client.capabilities`；
3. **路由选择**：按 capabilities 选择要拉取的路由，路由集合固定为：`falco`、`suricata`、`filebeat`；
4. **HTTP 拉取**：逐路由发送 HTTP GET 请求：`{listen_url}/{route}`；
5. **事件提取**：提取响应体中的 `data[]` 事件列表并汇总为本 tick 的事件列表；
6. **状态更新**：逐客户机写回注册表的 `poll.*` 状态字段；
7. **事件存储**（Step 2）：调用 `store_events()` 将本 tick 的事件列表写入 OpenSearch（Telemetry/Raw Findings/Canonical 按路由入库）；
8. **数据分析**（Step 3）：调用 `run_data_analysis()` 执行检测与告警融合（Raw → Canonical），写回 OpenSearch；
9. **图谱入库**（Step 4）：调用 Neo4j 入图流程（Telemetry + Canonical），将本 tick 产生的数据写入图谱。

相关模块入口：

- Step 2：`backend/app/services/opensearch/storage.py:store_events()`
- Step 3：`backend/app/services/opensearch/analysis.py:run_data_analysis()`
- Step 4：`backend/app/services/neo4j/ingest.py:ingest_from_opensearch_ingested_window()`

## 4. 状态更新与错误处理

### 4.1 轮询状态机

轮询服务的状态转换逻辑：

```mermaid
stateDiagram-v2
    [*] --> Idle: 服务启动

    Idle --> Polling: 定时器触发<br/>(每 5 秒)

    Polling --> Fetching: 读取注册表<br/>开始遍历客户机

    Fetching --> Processing: 拉取客户机数据<br/>(falco/suricata/filebeat)

    Processing --> Success: 数据拉取成功
    Processing --> Error: 数据拉取失败

    Success --> Idle: 更新 poll.status=success<br/>更新 poll.last_seen<br/>进入下一轮

    Error --> Idle: 更新 poll.status=error<br/>记录 poll.last_error<br/>下一轮重试

    note right of Polling
        单定时器 tick
        遍历所有客户机
    end note

    note right of Error
        失败不阻塞其他客户机
        下一轮自动重试
    end note
```

**状态说明**：

- **Idle**：空闲等待状态，等待定时器触发；
- **Polling**：轮询进行中，从注册表读取客户机列表；
- **Fetching**：拉取客户机数据（HTTP 请求客户机接口）；
- **Processing**：处理拉取的数据（提取事件、更新状态）；
- **Success**：单个客户机轮询成功；
- **Error**：单个客户机轮询失败。

### 4.2 故障处理策略

轮询服务对每个客户机维护以下固定错误处理语义：

1. 任一数据源拉取失败不阻塞其他数据源拉取；
2. 任一客户机轮询失败不阻塞其他客户机轮询；
3. 失败信息写入 `poll.last_error`，状态写入 `poll.status`，下一轮继续重试；
4. 轮询循环永不因单个客户机异常退出；
5. OpenSearch / Neo4j 属于中心机必选依赖：当 Step 3 或 Step 4 失败时，**轮询任务应快速失败并暴露错误**（用于靶场联调/验收时及时发现问题），但**不应在后台任务里直接 `os._exit(1)` 杀死 FastAPI 进程**（会导致服务"看起来卡死/不可控退出"，也不利于排障与恢复）。

### 4.3 故障处理时序图

完整的超时、重试、错误记录流程：

```mermaid
sequenceDiagram
    autonumber

    participant Timer as 定时器
    participant Poller as 轮询服务
    participant Client as 客户机
    participant Registry as client-registry<br/>(OpenSearch)
    participant Pipeline as 中心机流水线

    Note over Timer,Pipeline: 正常流程

    Timer->>Poller: 触发 tick (每 5 秒)
    Poller->>Registry: 读取客户机列表
    Registry-->>Poller: 返回客户机信息

    Poller->>Client: GET /falco
    Client-->>Poller: 返回 falco 事件

    Poller->>Client: GET /suricata
    Client-->>Poller: 返回 suricata 事件

    Poller->>Client: GET /filebeat
    Client-->>Poller: 返回 filebeat 事件

    Poller->>Registry: 更新 poll.status=success<br/>poll.last_seen=now

    Poller->>Pipeline: store_events()
    Pipeline->>Registry: 写入 Telemetry/Raw Findings

    Poller->>Pipeline: run_data_analysis()
    Pipeline->>Registry: 写入 Canonical Findings

    Poller->>Pipeline: ingest_from_opensearch_ingested_window()
    Pipeline->>Pipeline: 写入 Neo4j 图谱

    Note over Timer,Pipeline: 超时故障处理

    Timer->>Poller: 触发下一 tick
    Poller->>Registry: 读取客户机列表

    Poller->>Client: GET /falco
    Note over Client: 超时 (5 秒)
    Client--xPoller: HTTP timeout

    Poller->>Poller: 捕获超时异常
    Poller->>Registry: 更新 poll.status=error<br/>poll.last_error="Timeout: falco"

    Poller->>Client: GET /suricata
    Client-->>Poller: 返回 suricata 事件<br/>(不因 falco 失败而阻塞)

    Poller->>Client: GET /filebeat
    Client-->>Poller: 返回 filebeat 事件

    Poller->>Registry: 更新 poll.status=partial_success<br/>记录部分成功

    Poller->>Pipeline: 继续处理已拉取的事件

    Note over Timer,Pipeline: 流水线故障处理

    Timer->>Poller: 触发新 tick
    Poller->>Registry: 读取客户机列表
    Poller->>Client: 拉取所有数据源
    Client-->>Poller: 返回所有事件

    Poller->>Registry: 更新 poll.status=success

    Poller->>Pipeline: store_events()
    Pipeline-->>Poller: 成功

    Poller->>Pipeline: run_data_analysis()
    Pipeline--xPoller: OpenSearch 连接失败

    Poller->>Poller: 检测到必选依赖失败
    Poller--xTimer: 抛出异常<br/>停止轮询任务<br/>不杀死 FastAPI 进程

    Note over Poller: 日志记录完整错误堆栈<br/>用于靶场联调排查
```

**时序说明**：

1. **正常流程**：定时器触发轮询服务 → 拉取所有客户机的三个数据源 → 更新注册表 → 流水线处理（存储/分析/入图）；
2. **超时处理**：单个数据源超时（如 falco）不阻塞其他数据源（suricata/filebeat 继续拉取）→ 记录错误到 `poll.last_error` → 状态标记为 `partial_success` → 继续处理已拉取的事件；
3. **流水线故障**：当 OpenSearch/Neo4j 等必选依赖失败时 → 抛出异常停止轮询任务 → 记录完整错误堆栈 → 不杀死 FastAPI 进程（便于排障与恢复）。
